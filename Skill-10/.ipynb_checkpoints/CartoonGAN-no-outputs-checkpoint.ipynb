{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T08:34:15.624989Z",
     "start_time": "2020-12-31T08:34:14.726844Z"
    },
    "collapsed": true,
    "id": "14h4ejQKFVe9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T08:34:18.595481Z",
     "start_time": "2020-12-31T08:34:15.626834Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UnlKaodtFVe9",
    "outputId": "f865a449-9fb3-4a24-c965-9399357d42ec"
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "print (tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JHQwB2seggzy",
    "outputId": "1c6110ac-7440-44a2-dfbb-a0eb5df7a464"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lkpw_LFJf9fb",
    "outputId": "49423965-b51a-4fb0-c7b6-17baed85adc0"
   },
   "outputs": [],
   "source": [
    "!unzip /content/gdrive/MyDrive/GAN_datasets/photo2cartoon.zip -d /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mon5F43e2wwk",
    "outputId": "e1477b8f-5c64-49eb-f967-634716f0283c"
   },
   "outputs": [],
   "source": [
    "!ls /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "NQQBPNG2h-Cy"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "faces = glob.glob('/trainA/*.jpg')\n",
    "cartoons = glob.glob(\"/trainB/*.png\")\n",
    "faces_test = glob.glob('/testA/*.jpg')\n",
    "cartoons_test = glob.glob('/testB/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T08:34:18.768831Z",
     "start_time": "2020-12-31T08:34:18.596958Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "path = '/Users/k15/Downloads/selfie2anime/'\n",
    "faces = glob.glob(path + '/trainA/*.jpg')\n",
    "cartoons = glob.glob(path + \"../cartoonset10k/*.png\")\n",
    "faces_test = glob.glob(path + '/testA/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T08:34:18.777768Z",
     "start_time": "2020-12-31T08:34:18.769875Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZS3Lq6rHh-Fe",
    "outputId": "532a490d-1d23-47d7-a422-9ef250b2a2a6"
   },
   "outputs": [],
   "source": [
    "len(faces), len(cartoons), len(faces_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T08:34:19.365939Z",
     "start_time": "2020-12-31T08:34:19.237672Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tJ0DxtPLh-hQ",
    "outputId": "4f737457-524c-4f44-b80d-3cf5cec9267c"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "for file in cartoons[:10]:\n",
    "    img = cv2.imread(file)\n",
    "    print (img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T08:34:22.288521Z",
     "start_time": "2020-12-31T08:34:21.002134Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "06Fm26_-h-kE",
    "outputId": "0be9f751-2ff0-49eb-cc97-84e5d82fb0c2"
   },
   "outputs": [],
   "source": [
    "print (\"Human Faces\")\n",
    "for k in range(2):\n",
    "    plt.figure(figsize=(13, 13))\n",
    "    for j in range(6):\n",
    "        file = np.random.choice(faces)\n",
    "        img = cv2.imread(file)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        plt.subplot(660 + 1 + j)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        #plt.title(trainY[i])\n",
    "    plt.show()\n",
    "\n",
    "print (\"-\"*80)\n",
    "print (\"Cartoon Faces\")\n",
    "for k in range(2):\n",
    "    plt.figure(figsize=(13, 13))\n",
    "    for j in range(6):\n",
    "        file = np.random.choice(cartoons)\n",
    "        img = cv2.imread(file)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img[120:380,120:380]\n",
    "        plt.subplot(660 + 1 + j)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        #plt.title(trainY[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxFTsuaGFVe-"
   },
   "source": [
    "# Generator Model (U-Net Like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T08:34:24.817791Z",
     "start_time": "2020-12-31T08:34:24.724841Z"
    },
    "collapsed": true,
    "id": "EYv50QYoF3wd"
   },
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T08:34:25.338365Z",
     "start_time": "2020-12-31T08:34:25.328106Z"
    },
    "collapsed": true,
    "id": "uZtQ7KmJfoFl"
   },
   "outputs": [],
   "source": [
    "def encoder_layer(input_layer, filters, bn=True):\n",
    "    x = tensorflow.keras.layers.Conv2D(filters, kernel_size=(4,4), strides=(2,2), padding='same')(input_layer)\n",
    "    x = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "    if bn:\n",
    "        #x = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
    "        x = tfa.layers.InstanceNormalization()(x)\n",
    "    return x\n",
    "\n",
    "def decoder_layer(input_layer, skip_input, filters):\n",
    "    #x = tensorflow.keras.layers.UpSampling2D(size=2)(input_layer)\n",
    "    x = tensorflow.keras.layers.Conv2DTranspose(filters, kernel_size=(4,4), strides=(2,2), padding='same')(input_layer)\n",
    "    x = tensorflow.keras.layers.Activation('relu')(x)\n",
    "    #x = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
    "    x = tfa.layers.InstanceNormalization()(x)\n",
    "    x = tensorflow.keras.layers.Concatenate()([x, skip_input])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T08:34:26.773290Z",
     "start_time": "2020-12-31T08:34:25.755300Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3-DrN_4tfoFm",
    "outputId": "83bc272a-a271-4886-b2dc-0d03416a7b34"
   },
   "outputs": [],
   "source": [
    "def make_generator():\n",
    "    source_image = tensorflow.keras.layers.Input(shape=(128, 128, 3))\n",
    "\n",
    "    e1 = encoder_layer(source_image, 64, bn=False)\n",
    "    e2 = encoder_layer(e1, 128)\n",
    "    e3 = encoder_layer(e2, 256)\n",
    "    # e4 = encoder_layer(e3, 256)\n",
    "    e5 = encoder_layer(e3, 512)\n",
    "    e6 = encoder_layer(e5, 512)\n",
    "    e7 = encoder_layer(e6, 512)\n",
    "\n",
    "    bottle_neck = tensorflow.keras.layers.Conv2D(512, (4,4), strides=(2,2), padding='same')(e7)\n",
    "    b = tensorflow.keras.layers.Activation('relu')(bottle_neck)\n",
    "\n",
    "    d1 = decoder_layer(b, e7, 512)\n",
    "    d2 = decoder_layer(d1, e6, 512)\n",
    "    d3 = decoder_layer(d2, e5, 512)\n",
    "    # d4 = decoder_layer(d3, e4, 256)\n",
    "    d5 = decoder_layer(d3, e3, 256)\n",
    "    d6 = decoder_layer(d5, e2, 128)\n",
    "    d7 = decoder_layer(d6, e1, 64)\n",
    "\n",
    "    decoded = tensorflow.keras.layers.Conv2DTranspose(3, kernel_size=(4,4), strides=(2,2), padding='same')(d7)\n",
    "    translated_image = tensorflow.keras.layers.Activation('tanh')(decoded)\n",
    "    return source_image, translated_image\n",
    "\n",
    "source_image, translated_image = make_generator()\n",
    "generator_network = tensorflow.keras.models.Model(inputs=source_image, outputs=translated_image)\n",
    "print (generator_network.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eQOF8YEKfoFm"
   },
   "source": [
    "# Discriminator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T08:34:26.778107Z",
     "start_time": "2020-12-31T08:34:26.774425Z"
    },
    "collapsed": true,
    "id": "gXTFSDKafoFm"
   },
   "outputs": [],
   "source": [
    "def my_conv_layer(input_layer, filters, bn=True):\n",
    "    x = tensorflow.keras.layers.Conv2D(filters, kernel_size=(4,4), strides=(2,2), padding='same')(input_layer)\n",
    "    x = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "    if bn:\n",
    "        #x = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
    "        x = tfa.layers.InstanceNormalization()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T08:34:27.207645Z",
     "start_time": "2020-12-31T08:34:27.070146Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1GCaEdctfoFn",
    "outputId": "8455b2b9-adb3-4931-f96c-1dadfc2c1956"
   },
   "outputs": [],
   "source": [
    " def make_discriminator():\n",
    "    target_image_input = tensorflow.keras.layers.Input(shape=(128, 128, 3))\n",
    "\n",
    "    x = my_conv_layer(target_image_input, 64, bn=False)\n",
    "    x = my_conv_layer(x, 128)\n",
    "    x = my_conv_layer(x, 256)\n",
    "    # x = my_conv_layer(x, 512)\n",
    "    x = my_conv_layer(x, 512)\n",
    "\n",
    "    patch_features = tensorflow.keras.layers.Conv2D(1, kernel_size=(4,4), strides=(1,1), padding='same')(x)\n",
    "    return target_image_input, patch_features\n",
    "\n",
    "\n",
    "target_image_input, patch_features = make_discriminator()\n",
    "discriminator_network = tensorflow.keras.models.Model(inputs=target_image_input, outputs=patch_features)\n",
    "\n",
    "print (discriminator_network.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T08:34:27.466219Z",
     "start_time": "2020-12-31T08:34:27.447094Z"
    },
    "collapsed": true,
    "id": "tMc1CyNNFVe-"
   },
   "outputs": [],
   "source": [
    "adam_optimizer = tensorflow.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "discriminator_network.compile(loss='mse', optimizer=adam_optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "99IlAN3AFVe-"
   },
   "source": [
    "# CARTOON-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T08:34:29.062827Z",
     "start_time": "2020-12-31T08:34:28.771841Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mjnxFr21FVe-",
    "outputId": "02f44832-ac3b-4864-9cb5-4cc950d9486b"
   },
   "outputs": [],
   "source": [
    "source_image = tensorflow.keras.layers.Input(shape=(128, 128, 3))\n",
    "\n",
    "# Domain Transfer\n",
    "fake_cartoon = generator_network(source_image)\n",
    "  \n",
    "discriminator_network.trainable=False\n",
    "\n",
    "# Tell Real vs Fake\n",
    "real_vs_fake = discriminator_network(fake_cartoon)\n",
    "\n",
    "cartoon_gan = tensorflow.keras.models.Model(inputs = source_image, outputs = [real_vs_fake, fake_cartoon])\n",
    "cartoon_gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Gi83UW7B8x8"
   },
   "source": [
    "# VGG features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T08:34:30.299495Z",
     "start_time": "2020-12-31T08:34:29.868174Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-hpFT1JSBJ-q",
    "outputId": "c1f08727-5e59-4db0-8ad1-22dd2e8fa7e1"
   },
   "outputs": [],
   "source": [
    "image_input = tensorflow.keras.layers.Input(shape=(128, 128, 3))\n",
    "\n",
    "pre_trained_vgg = tensorflow.keras.applications.vgg19.VGG19(weights='imagenet', input_shape=(128, 128, 3), include_top=False)\n",
    "pre_trained_vgg_model = tensorflow.keras.models.Model(inputs=pre_trained_vgg.input, outputs=pre_trained_vgg.get_layer('block4_conv4').output)\n",
    "\n",
    "pre_trained_image_feautures = pre_trained_vgg_model(image_input)\n",
    "\n",
    "custom_vgg = tensorflow.keras.models.Model(inputs=image_input, outputs=pre_trained_image_feautures)\n",
    "print (custom_vgg.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7DxGPiGBRx3"
   },
   "source": [
    "# Custom GAN Loss (vgg content Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T08:34:31.228266Z",
     "start_time": "2020-12-31T08:34:31.224255Z"
    },
    "collapsed": true,
    "id": "EBTLUkyCBKb6"
   },
   "outputs": [],
   "source": [
    "def custom_gan_loss(y_true, y_pred):\n",
    "    custom_vgg.trainable=False\n",
    "    y_true_features = custom_vgg(y_true)\n",
    "    y_pred_features = custom_vgg(y_pred)\n",
    "    content_loss = tensorflow.compat.v1.losses.absolute_difference(y_true_features, y_pred_features)\n",
    "    return content_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MFyjhkyCFVe_"
   },
   "source": [
    "# Compiling Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T09:17:08.828090Z",
     "start_time": "2020-12-31T09:17:08.816614Z"
    },
    "collapsed": true,
    "id": "rPG_olwXFVe_"
   },
   "outputs": [],
   "source": [
    "cartoon_gan.compile(loss=['mse', custom_gan_loss], optimizer=adam_optimizer, loss_weights=[1, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5RpVWMO8FVe_"
   },
   "source": [
    "# Define Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T08:34:36.594413Z",
     "start_time": "2020-12-31T08:34:36.498364Z"
    },
    "collapsed": true,
    "id": "pTSivi-dFVe_"
   },
   "outputs": [],
   "source": [
    "def faces_to_cartoons(faces, generator_network):\n",
    "    generated_samples = generator_network.predict_on_batch(faces)\n",
    "    return generated_samples\n",
    "\n",
    "def do_smoothing(img):\n",
    "    # taken from https://github.com/penny4860/Keras-CartoonGan/blob/master/cartoon/utils.py\n",
    "    kernel_size = 5\n",
    "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "    gauss = cv2.getGaussianKernel(kernel_size, 0)\n",
    "    gauss = gauss * gauss.transpose(1, 0)\n",
    "\n",
    "    rgb_img = img\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    pad_img = np.pad(rgb_img, ((2,2), (2,2), (0,0)), mode='reflect')\n",
    "    edges = cv2.Canny(gray_img, 100, 200)\n",
    "    dilation = cv2.dilate(edges, kernel)\n",
    "\n",
    "    gauss_img = np.copy(rgb_img)\n",
    "    idx = np.where(dilation != 0)\n",
    "    for i in range(np.sum(dilation != 0)):\n",
    "        gauss_img[idx[0][i], idx[1][i], 0] = np.sum(np.multiply(pad_img[idx[0][i]:idx[0][i] + kernel_size, idx[1][i]:idx[1][i] + kernel_size, 0], gauss))\n",
    "        gauss_img[idx[0][i], idx[1][i], 1] = np.sum(np.multiply(pad_img[idx[0][i]:idx[0][i] + kernel_size, idx[1][i]:idx[1][i] + kernel_size, 1], gauss))\n",
    "        gauss_img[idx[0][i], idx[1][i], 2] = np.sum(np.multiply(pad_img[idx[0][i]:idx[0][i] + kernel_size, idx[1][i]:idx[1][i] + kernel_size, 2], gauss))\n",
    "\n",
    "    return gauss_img\n",
    "\n",
    "def get_training_samples(batch_size):\n",
    "    random_files = np.random.choice(faces, size=batch_size)\n",
    "    images = []\n",
    "    for file in random_files:\n",
    "        img = cv2.imread(file)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (128, 128))\n",
    "        images.append((img-127.5)/127.5)\n",
    "    face_images = np.array(images)\n",
    "\n",
    "    random_files = np.random.choice(cartoons, size=batch_size)\n",
    "    images = []\n",
    "    smooth_images = []\n",
    "    for file in random_files:\n",
    "        img = cv2.imread(file)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img[120:380,120:380]\n",
    "        img = cv2.resize(img, (128, 128))\n",
    "        smooth = do_smoothing(img)\n",
    "        images.append((img-127.5)/127.5)\n",
    "        smooth_images.append((smooth-127.5)/127.5)\n",
    "    cartoon_images = np.array(images)\n",
    "    cartoon_smooth_images = np.array(smooth_images)\n",
    "    return face_images, cartoon_images, cartoon_smooth_images\n",
    "\n",
    "def show_generator_results(generator_network):\n",
    "    images = []\n",
    "    for j in range(5):\n",
    "        file = np.random.choice(faces)\n",
    "        img = cv2.imread(file)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (128, 128))\n",
    "        images.append(img)\n",
    "\n",
    "    print ('Human Face Images')\n",
    "    plt.figure(figsize=(13, 13))\n",
    "    for j, img in enumerate(images):\n",
    "        plt.subplot(550 + 1 + j)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        #plt.title(trainY[i])\n",
    "    plt.show()\n",
    "\n",
    "    print ('Cartoon Version')\n",
    "    plt.figure(figsize=(13, 13))\n",
    "    for j, img in enumerate(images):\n",
    "        img = (img-127.5)/127.5\n",
    "        output = faces_to_cartoons(np.array([img]), generator_network)[0]\n",
    "        output = (output+1.0)/2.0\n",
    "        plt.subplot(550 + 1 + j)\n",
    "        plt.imshow(output)\n",
    "        plt.axis('off')\n",
    "        #plt.title(trainY[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uaS06EGZMqZ9"
   },
   "source": [
    "## Check smooth version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T08:34:37.764501Z",
     "start_time": "2020-12-31T08:34:37.325716Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "id": "KYFHfmtDMTzC",
    "outputId": "b014f7b5-0245-41b7-96d8-7d214855b9bf"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(cartoons[4])\n",
    "img = img[120:380,120:380]\n",
    "img = cv2.resize(img, (128, 128))\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "plt.imshow(do_smoothing(img))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEOpY_BZFVe_"
   },
   "source": [
    "# Training GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T08:34:38.261173Z",
     "start_time": "2020-12-31T08:34:38.257592Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lg6OKd4qmIdh",
    "outputId": "d9b6c646-94d6-411f-9a33-de654d368e04"
   },
   "outputs": [],
   "source": [
    "len(faces), len(cartoons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-31T09:17:12.714Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 821
    },
    "id": "E_nihCaQFVe_",
    "outputId": "0f9ed7d2-aeea-4262-e208-e8f41270f0d2",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "batch_size = 4\n",
    "steps = 3400\n",
    "\n",
    "for i in range(0, epochs):\n",
    "    for j in range(steps): \n",
    "        if j%200 == 0:\n",
    "            show_generator_results(generator_network) \n",
    "            generator_network.save('/Users/k15/Downloads/cartoonset10k/weights/mod_'+str(i)+str(j))\n",
    "\n",
    "        human_faces, cartoon_faces, smooth_cartoon_faces = get_training_samples(batch_size)\n",
    "\n",
    "        fake_patch = np.zeros((batch_size, 8, 8, 1))\n",
    "        real_patch = np.ones((batch_size, 8, 8, 1))\n",
    "        \n",
    "        fake_cartoon_faces = generator_network(human_faces)\n",
    "        \n",
    "        # Updating Discriminator weights\n",
    "        discriminator_network.trainable=True\n",
    "        loss_d_real = discriminator_network.train_on_batch(cartoon_faces, real_patch)\n",
    "        loss_d_smooth = discriminator_network.train_on_batch(smooth_cartoon_faces, fake_patch)\n",
    "        loss_d_fake = discriminator_network.train_on_batch(fake_cartoon_faces, fake_patch)\n",
    "        \n",
    "        loss_d = np.add(loss_d_real, np.add(loss_d_smooth, loss_d_fake))/3.0\n",
    "        \n",
    "        # Make the Discriminator belive that these are real samples and calculate loss to train the generator\n",
    "        discriminator_network.trainable=False\n",
    "\n",
    "        # Updating Generator weights\n",
    "        loss_g = cartoon_gan.train_on_batch(human_faces,[real_patch, human_faces])\n",
    "        \n",
    "        if j%100 == 0:\n",
    "            print (\"Epoch:%.0f, Step:%.0f, D-Loss:%.3f, D-Acc:%.3f, G-Loss:%.3f\"%(i,j,loss_d[0],loss_d[1]*100,loss_g[0]))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "_jgpDWaA5ncV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Generative Adversarial Network.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
